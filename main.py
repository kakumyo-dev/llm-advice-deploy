from flask import Flask, jsonify
from google.cloud import bigquery
from dotenv import load_dotenv
import os
import openai
print(f"âœ… openai version: {openai.__version__}")
from openai import OpenAI
import json
from datetime import date

app = Flask(__name__)

print("âœ… Flask app initialized")

load_dotenv()  # .env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ç’°å¢ƒå¤‰æ•°ã«åæ˜ 
print("âœ… .env loaded")

api_key = os.environ.get("OPENAI_API_KEY")
if not api_key:
    print("âŒ OPENAI_API_KEY is not set")
else:
    print(f"âœ… OPENAI_API_KEY loaded: {api_key[:5]}***")

@app.route("/")
def index():
    try:
        print("ðŸ”„ Initializing OpenAI client...")
        openai_client = OpenAI(api_key=api_key)
        print("âœ… OpenAI client initialized")

        bigquery_client = bigquery.Client()
        query = """
WITH sleep AS (
  SELECT 
    summary_date,
    participant_uid,
    score,
    total,
    light,
    rem,
    deep
  FROM `sic-ouraring-verify.gcube.sleep`
  WHERE total >= 3600
),
activity AS (
  SELECT 
    summary_date,
    participant_uid,
    non_wear,
    inactive,
    inactivity_alerts,
    steps
  FROM `sic-ouraring-verify.gcube.activity`
  WHERE non_wear <= 14400
)

SELECT 
  s.summary_date AS date,
  s.score AS sleep_score,
  s.total AS total_sleep_seconds,
  s.light AS light_sleep_seconds,
  s.rem AS rem_sleep_seconds,
  s.deep AS deep_sleep_seconds,
  a.steps,
FROM sleep s
LEFT JOIN activity a
  ON s.summary_date = a.summary_date AND s.participant_uid = a.participant_uid
WHERE s.summary_date BETWEEN DATE_TRUNC(CURRENT_DATE(), MONTH) AND LAST_DAY(CURRENT_DATE())
ORDER BY s.summary_date ASC
LIMIT 1000
        """
        query_job = bigquery_client.query(query)
        results = query_job.result()
        data_list = [dict(row.items()) for row in results]

        prompt_data = "\n".join([str(row) for row in data_list])
        print(f"ðŸ“‹ Prompt data prepared: {prompt_data}")

        # OpenAI GPT-4o ã«ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        response = openai_client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": """ã‚ãªãŸã¯å°‚é–€çš„ãªåŒ»ç™‚çŸ¥è­˜ã‚’æŒã¤åŒ»å¸«ã§ã™ã€‚
ä»¥ä¸‹ã®å½¢å¼ã®JSONã§å›žç­”ã—ã¦ãã ã•ã„ï¼š
{
    "sleep_analysis": "ç¡çœ ã«é–¢ã™ã‚‹åˆ†æžã¨ã‚¢ãƒ‰ãƒã‚¤ã‚¹",
    "activity_analysis": "æ´»å‹•é‡ã«é–¢ã™ã‚‹åˆ†æžã¨ã‚¢ãƒ‰ãƒã‚¤ã‚¹",
    "readiness_analysis": "ä½“èª¿ã«é–¢ã™ã‚‹åˆ†æžã¨ã‚¢ãƒ‰ãƒã‚¤ã‚¹",
    "recommendations": "å…·ä½“çš„ãªæ”¹å–„ææ¡ˆ",
    "overall_assessment": "ç·åˆçš„ãªè©•ä¾¡"
}
                 
æœ€çµ‚å¿œç­”ã¯ã€"{"ã§å§‹ã¾ã‚Š"}"ã§çµ‚ã‚ã‚‹ã€‚ã¾ãŸã¯"["ã§å§‹ã¾ã‚Š"]"ã§çµ‚ã‚ã‚‹JSONã®ã¿ã‚’å‡ºåŠ›ã—ã€JSONä»¥å¤–ã®æ–‡å­—ã¯ä¸€åˆ‡å¿œç­”ã«å«ã‚ãªã„ã§ãã ã•ã„ã€‚"""},
                {"role": "user", "content": f"ä»¥ä¸‹ã®OuraRingã‹ã‚‰å–å¾—ã—ãŸå¥åº·ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åŒ»å­¦çš„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ãã ã•ã„ï¼š\n\n{prompt_data}"}
            ]
        )

        llm_advice_content = response.choices[0].message.content
        print(f"ðŸ’¬ GPT response: {llm_advice_content}")

        # ãƒžãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯è¨˜æ³•ã‚’é™¤åŽ»
        llm_advice_content = llm_advice_content.replace("```json", "").replace("```", "").strip()

        # JSONæ–‡å­—åˆ—ã‚’Pythonã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›
        try:
            advice_data = json.loads(llm_advice_content)
        except json.JSONDecodeError as e:
            print(f"âŒ Failed to parse JSON response: {e}")
            return jsonify({"error": "Invalid JSON response from GPT"}), 500

        # BigQueryã«ä¿å­˜
        table_id = "llm_advicebot.llm_advice_makino"
        rows_to_insert = [{
            "summary_date": date.today().isoformat(),  # ç¾åœ¨ã®æ—¥ä»˜ã‚’ä½¿ç”¨
            "sleep_analysis": advice_data.get("sleep_analysis", ""),
            "activity_analysis": advice_data.get("activity_analysis", ""),
            "readiness_analysis": advice_data.get("readiness_analysis", ""),
            "recommendations": advice_data.get("recommendations", ""),
            "overall_assessment": advice_data.get("overall_assessment", "")
        }]
        errors = bigquery_client.insert_rows_json(table_id, rows_to_insert)
        if errors:
            print(f"âŒ Failed to insert rows: {errors}")
            return jsonify({"error": "BigQuery insert failed", "details": errors}), 500

        print("âœ… GPT response saved to BigQuery")

        # GPTã®å¿œç­”ã‚’è¿”å´
        return llm_advice_content
    except Exception as e:
        print(f"âŒ Exception occurred: {e}")
        return jsonify({"error": str(e)}), 500